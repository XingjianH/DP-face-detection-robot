{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df07e8e6",
   "metadata": {},
   "source": [
    "#  Reconnaissance de visages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c26bf9",
   "metadata": {},
   "source": [
    "# datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38934738",
   "metadata": {},
   "source": [
    "detec visage dans image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5009382",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "def face_detect_demo():\n",
    "#gary\n",
    "    gary = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "# haarcascade_frontalface_alt2.xml\n",
    "    face_detect = cv.CascadeClassifier('C:\\\\Users\\\\josephine\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python37\\\\Lib\\\\site-packages\\\\cv2\\\\data\\\\haarcascade_frontalface_alt2.xml')\n",
    "# detcte plusieur visage\n",
    "    face = face_detect.detectMultiScale(gary)\n",
    "# utilise une rectangle pour detec visage\n",
    "    for x,y,w,h in face:\n",
    "       cv.rectangle(img,(x,y),(x+w,y+h),color=(0,0,255),thickness=2)\n",
    "    cv.imshow('result',img)\n",
    "img = cv.imread('D:\\\\deep learning\\\\opencv\\\\photo.jpg')\n",
    "face_detect_demo()\n",
    "while True:\n",
    "     if ord('q') == cv.waitKey(0):\n",
    "         break\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174caba0",
   "metadata": {},
   "source": [
    "capture et sauvager les visage ce que obtenir dans le camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "645ef6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "#utilise un fonction pour dectec le visage\n",
    "def face_detect_demo(img,count):\n",
    "    #gary = cv.cvtColor(img,cv.COLOR_RGB2GRAY)\n",
    "    face_detect = cv.CascadeClassifier('C:\\\\Users\\\\josephine\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python37\\\\Lib\\\\site-packages\\\\cv2\\\\data\\\\haarcascade_frontalface_alt2.xml')\n",
    "    face = face_detect.detectMultiScale(img)#gary\n",
    "    # utilise une rectangle pour detec visage et sauvage le  visage dans rectangle\n",
    "    for x,y,w,h in face:\n",
    "       img = cv.rectangle(img,(x-20,y-20),(x+w+20,y+h+20),color=(0,0,255),thickness=2)\n",
    "       image = cv.resize(img[y-20:y + h+20, x-20:x + w+20], (300, 300))#gary\n",
    "       cv.imwrite(\"D:/User.\" + str(count) + '.jpg', image)\n",
    "    cv.imshow('result',img)\n",
    "\n",
    "#lire camera\n",
    "cap = cv.VideoCapture(0)\n",
    "cap.read()\n",
    "count = 0\n",
    "#utilise un boucle \n",
    "while True:\n",
    "    f,frame = cap.read()\n",
    "    if not f:\n",
    "        break\n",
    "    else:\n",
    "        count =count + 1\n",
    "    #utilise fonction\n",
    "    face_detect_demo(frame,count)\n",
    "    #si clique q,nous avons sorti le boucle while\n",
    "    if ord('q') == cv.waitKey(10):\n",
    "        break\n",
    "cv.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30c2d5c",
   "metadata": {},
   "source": [
    "# apprantisage "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d992bef1",
   "metadata": {},
   "source": [
    "utilise pytroch pour apprantisage et valide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bbb19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "\n",
    "#create a CNN\n",
    "#avec deux couche de convolution, trois couche complètement connectée, deux couche de pooling\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.name = \"CNN for face\"\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5)\n",
    "        self.pool1 = nn.MaxPool2d(2,2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5)\n",
    "        self.pool2 = nn.MaxPool2d(2,2)\n",
    "\n",
    "        #self.conv3 = nn.Conv2d(in_channels=32, out_channels=48, kernel_size=5)\n",
    "        #self.pool3 = nn.MaxPool2d(2,2)\n",
    "\n",
    "        self.fc1 = nn.Linear(32*22*22,120)\n",
    "        self.fc2 = nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))    # input(3, 100, 100) output(16, 96, 96)\n",
    "        x = self.pool1(x)            # output(16, 48, 48)\n",
    "        x = F.relu(self.conv2(x))    # output(32, 44, 44)\n",
    "        x = self.pool2(x)            # output(32, 22, 22)\n",
    "        #x = F.relu(self.conv3(x))    # output(48, 18, 18)\n",
    "        #x = self.pool3(x)            # output(48, 9, 9)\n",
    "\n",
    "        x = torch.flatten(x, 1)     #aplatissement\n",
    "\n",
    "        x = F.relu(self.fc1(x))      # output(120)\n",
    "        x = F.relu(self.fc2(x))      # output(84)\n",
    "        x = self.fc3(x)          # output(10)\n",
    "        return x\n",
    "    \n",
    "#root\n",
    "#train_dir='/content/drive/MyDrive/imageLUO'\n",
    "train_dir = './imagLUO/train'\n",
    "\n",
    "#size\n",
    "im_w, im_h = 100, 100\n",
    "transform = transforms.Compose([\n",
    "                 transforms.Resize((im_w, im_h)),\n",
    "                 transforms.ToTensor(),   #car la transformation qui suit porte sur des tenseurs\n",
    "                ])\n",
    "\n",
    "#import data\n",
    "full_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "#split dataset for train/test\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "#batch et loader data\n",
    "batch_size = 100\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#put data into graphics card\n",
    "#device = \"cpu\" #ou \"cuda\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "summary(model, (3, im_w, im_h))\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)    #utilisé par l'apprentissage (lr <-> learning rate)\n",
    "criterion = nn.CrossEntropyLoss()       #critère d'erreur en sortie (utilisé par l'apprentissage et le test)\n",
    "\n",
    "#function traning\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    data_len = len(train_loader.dataset)\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()                              #initialisation des gradients\n",
    "        output = model(data)                               #activation du réseau\n",
    "        loss = criterion(output, target)                   #calcul de l'erreur de sortie\n",
    "        loss.backward()                                    #rétro-propagation du gradient\n",
    "        optimizer.step()                                   #adaptation des poids des neurones\n",
    "        train_loss += loss.item()# * data.size(0)\n",
    "\n",
    "        pred = output.argmax(dim=1, keepdim=True)          # get the index of the max log-probability\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        if batch_idx % 200 == 0:\n",
    "            print('Train Epoch: {} [{}/{}]\\tTrain loss: {:.4f}'.format(\n",
    "                epoch, batch_idx * len(data), data_len, loss.item()))\n",
    "    train_loss /= data_len\n",
    "    accuracy = 100. * correct / data_len\n",
    "    print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain accuracy: {:.4f}'.format(\n",
    "                epoch, batch_idx * len(data), data_len, 100. * batch_idx / data_len, accuracy))\n",
    "    return train_loss, accuracy\n",
    "\n",
    "#function test\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss += criterion(output, target)#.item() * data.size(0)\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    loss /= len(test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    print('\\nTest set: Average test loss: {:.4f}, Test accuracy: ({:.2f}%)\\n'.format(loss, accuracy))\n",
    "    return loss, accuracy\n",
    "\n",
    "#function for design\n",
    "def matplot_loss(train_losses,test_losses,train_accuracies,test_accuracies):\n",
    "  plt.figure(figsize=(8, 8))\n",
    "  plt.subplot(2, 1, 1)\n",
    "\n",
    "  plt.title(\"loss vs learning epochs on face dataset\")\n",
    "  plt.ylabel(\"loss\")\n",
    "  plt.plot(train_losses, label='Train')\n",
    "  plt.plot(test_losses, label='Test')\n",
    "  plt.legend(loc=\"upper right\")\n",
    "  plt.subplot(2, 1, 2)\n",
    "\n",
    "  plt.title(\"accuracy vs learning epochs on face dataset\")\n",
    "  plt.xlabel(\"epochs\")\n",
    "  plt.ylabel(\"accuracy\")\n",
    "  plt.plot(train_accuracies, label='Train')\n",
    "  plt.plot(test_accuracies, label='Test')\n",
    "  plt.legend(loc=\"lower right\")\n",
    "  plt.show()\n",
    "\n",
    "#begin traning\n",
    "epochs = 50\n",
    "min_accuracy = 0\n",
    "test_losses, test_accuracies, train_losses, train_accuracies = [], [], [], []\n",
    "print('Learning (please wait)...')\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss, train_accuracy = train(model, device, train_loader, optimizer, epoch)\n",
    "    test_loss, test_accuracy = test(model, device, test_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "    #save most better poids\n",
    "    if test_accuracy > min_accuracy:\n",
    "      folder = './models/save_model'\n",
    "      if not os.path.exists(folder):\n",
    "        os.mkdir('./models/save_model')\n",
    "      min_accuracy=train_accuracy\n",
    "      torch.save(model.state_dict(),'./models/save_model/best_model.pth')\n",
    "      print('save epoch'+str(epoch))\n",
    "print('Done')\n",
    "matplot_loss(train_losses,test_losses,train_accuracies,test_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03630845",
   "metadata": {},
   "source": [
    "Tests de différents paramètres du RNC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73871a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def predict(model, image):\n",
    "    image = image.resize((100, 100))\n",
    "    np_img = np.array(image)                        # conversion en tableau numpy\n",
    "    image_tensor = torch.from_numpy(np_img)         # conversion en tenseur PyTorch\n",
    "    image_tensor = image_tensor.permute(2, 0, 1)    # nouvel ordre des dimensions\n",
    "    image_tensor = image_tensor.reshape([1, 3, np_img.shape[0], np_img.shape[1]]) # ajout d'une dimension (cf + haut)\n",
    "    output = model(image_tensor.float())        # application de l'image en entrée du réseau\n",
    "    index = output.data.cpu().numpy().argmax()\n",
    "    return index\n",
    " \n",
    "image_file1 = '/content/drive/MyDrive/deep learning/imageTest/EmmanuelTest.jpg'\n",
    "image_file2 = '/content/drive/MyDrive/deep learning/imageTest/HuangXingjiantest.jpg'\n",
    "image_file3 = '/content/drive/MyDrive/deep learning/imageTest/LUOWenqicolortest.jpg'\n",
    "image_file4 = '/content/drive/MyDrive/deep learning/imageTest/ValexTest.jpg'\n",
    "image_file5 = '/content/drive/MyDrive/deep learning/imageTest/unknownTest.jpg'\n",
    "\n",
    "model = Net()                                    # re-création d'un réseau de neurones (identique au précédent)\n",
    "model.load_state_dict(torch.load('./models/save_model/best_model.pth'))    # chargement du modèle\n",
    "model.eval()\n",
    "\n",
    "images = []\n",
    "img1 = Image.open(image_file1)\n",
    "img2 = Image.open(image_file2)\n",
    "img3 = Image.open(image_file3)\n",
    "img4 = Image.open(image_file4)\n",
    "img5 = Image.open(image_file5)\n",
    "images.append(img1)\n",
    "images.append(img2)\n",
    "images.append(img3)\n",
    "images.append(img4)\n",
    "images.append(img5)\n",
    "\n",
    "for i in range(5):\n",
    "  #programme principal\n",
    "  true_index = i            #classe \"Emmanuel\" : incdex = 0 classe \"HUANGXinjian\" : index = 1 ; classe \"LUOWenqi\" ; index = 2 ：classe \"Valex\" index = 3 : classe \"unknown\" index = 4\n",
    "\n",
    "  index = predict(model, images[i])\n",
    "  print('index : ', index)\n",
    "\n",
    "  #affichage du résultat sur l'image\n",
    "  classe = []    #nom des classes\n",
    "  classe.append('Emmanuel')\n",
    "  classe.append('HUANGXingjian')\n",
    "  classe.append('LUOWenqi')\n",
    "  classe.append('Valex')\n",
    "  classe.append('unknown')\n",
    "  if(true_index == index):\n",
    "      res = True\n",
    "  else:\n",
    "      res = False\n",
    "  test_loss, test_accuracy = test(model, device, test_loader)\n",
    "  plt.figure(figsize=(8, 8))\n",
    "  plt.subplot(5, 1, i+1)\n",
    "  plt.title('classe : ' + str(classe[index]) + ' (' + str(res) + ')')\n",
    "  plt.axis('off')\n",
    "  plt.imshow(images[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a8b091",
   "metadata": {},
   "source": [
    "# detection visage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040229f3",
   "metadata": {},
   "source": [
    "change FDDB dans pascal VOC fomat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef18dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/penolove/FDDB_DataSet_4_faster_rcnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370a8757",
   "metadata": {},
   "source": [
    "test de l’algorithme MobileNetV2-SSD avec image et video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88fd355",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image\n",
    "from vision.ssd.vgg_ssd import create_vgg_ssd, create_vgg_ssd_predictor\n",
    "from vision.ssd.mobilenetv1_ssd import create_mobilenetv1_ssd, create_mobilenetv1_ssd_predictor\n",
    "from vision.ssd.mobilenetv1_ssd_lite import create_mobilenetv1_ssd_lite, create_mobilenetv1_ssd_lite_predictor\n",
    "from vision.ssd.squeezenet_ssd_lite import create_squeezenet_ssd_lite, create_squeezenet_ssd_lite_predictor\n",
    "from vision.ssd.mobilenet_v2_ssd_lite import create_mobilenetv2_ssd_lite, create_mobilenetv2_ssd_lite_predictor\n",
    "from vision.ssd.mobilenetv3_ssd_lite import create_mobilenetv3_large_ssd_lite, create_mobilenetv3_small_ssd_lite\n",
    "from vision.utils.misc import Timer\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "net_type = 'mb2-ssd-lite'\n",
    "model_path = '/content/drive/MyDrive/deep learning/MobileNetSSD/mb2-ssd-lite-mp-0_686.pth'\n",
    "label_path = '/content/drive/MyDrive/deep learning/MobileNetSSD/voc-model-labels.txt'\n",
    "image_path = '/content/drive/MyDrive/FDDB_2010/JPEGImages/000000.jpg'\n",
    "\n",
    "class_names = [name.strip() for name in open(label_path).readlines()]\n",
    "\n",
    "if net_type == 'vgg16-ssd':\n",
    "    net = create_vgg_ssd(len(class_names), is_test=True)\n",
    "elif net_type == 'mb1-ssd':\n",
    "    net = create_mobilenetv1_ssd(len(class_names), is_test=True)\n",
    "elif net_type == 'mb1-ssd-lite':\n",
    "    net = create_mobilenetv1_ssd_lite(len(class_names), is_test=True)\n",
    "elif net_type == 'mb2-ssd-lite':\n",
    "    net = create_mobilenetv2_ssd_lite(len(class_names), is_test=True)\n",
    "elif net_type == 'mb3-large-ssd-lite':\n",
    "    net = create_mobilenetv3_large_ssd_lite(len(class_names), is_test=True)\n",
    "elif net_type == 'mb3-small-ssd-lite':\n",
    "    net = create_mobilenetv3_small_ssd_lite(len(class_names), is_test=True)\n",
    "elif net_type == 'sq-ssd-lite':\n",
    "    net = create_squeezenet_ssd_lite(len(class_names), is_test=True)\n",
    "else:\n",
    "    print(\"The net type is wrong. It should be one of vgg16-ssd, mb1-ssd and mb1-ssd-lite.\")\n",
    "net.load(model_path)\n",
    "\n",
    "if net_type == 'vgg16-ssd':\n",
    "    predictor = create_vgg_ssd_predictor(net, candidate_size=200)\n",
    "elif net_type == 'mb1-ssd':\n",
    "    predictor = create_mobilenetv1_ssd_predictor(net, candidate_size=200)\n",
    "elif net_type == 'mb1-ssd-lite':\n",
    "    predictor = create_mobilenetv1_ssd_lite_predictor(net, candidate_size=200)\n",
    "elif net_type == 'mb2-ssd-lite' or net_type == \"mb3-large-ssd-lite\" or net_type == \"mb3-small-ssd-lite\":\n",
    "    predictor = create_mobilenetv2_ssd_lite_predictor(net, candidate_size=200)\n",
    "elif net_type == 'sq-ssd-lite':\n",
    "    predictor = create_squeezenet_ssd_lite_predictor(net, candidate_size=200)\n",
    "else:\n",
    "    predictor = create_vgg_ssd_predictor(net, candidate_size=200)\n",
    "\n",
    "orig_image = cv2.imread(image_path)\n",
    "image = cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB)\n",
    "boxes, labels, probs = predictor.predict(image, 10, 0.4)\n",
    "\n",
    "for i in range(boxes.size(0)):\n",
    "    box = boxes[i, :]\n",
    "    cv2.rectangle(orig_image, (box[0], box[1]), (box[2], box[3]), (255, 255, 0), 4)\n",
    "    #label = f\"\"\"{voc_dataset.class_names[labels[i]]}: {probs[i]:.2f}\"\"\"\n",
    "    label = f\"{class_names[labels[i]]}: {probs[i]:.2f}\"\n",
    "    cv2.putText(orig_image, label,\n",
    "                (box[0] + 20, box[1] + 40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                1,  # font scale\n",
    "                (255, 0, 255),\n",
    "                2)  # line type\n",
    "plt.imshow(orig_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa05e1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#video\n",
    "import time\n",
    "import imutils\n",
    "from PIL import Image\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def draw_boxes(image, boxes, labels, probs):\n",
    "    for i in range(boxes.size(0)):\n",
    "        box = boxes[i, :]\n",
    "        cv2.rectangle(image, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), (255, 255, 0), 4)\n",
    "        label = f\"{class_names[labels[i]]}: {probs[i]:.2f}\"\n",
    "        cv2.putText(image, label,\n",
    "                    (int(box[0]) + 20, int(box[1]) + 40),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    1,  # font scale\n",
    "                    (255, 0, 255),\n",
    "                    2)  # line type\n",
    "    \n",
    "video_file = '/content/drive/MyDrive/deep learning/videoplayback.mp4'\n",
    "cap = cv2.VideoCapture(video_file)\n",
    "\n",
    "if (cap.isOpened() == False):\n",
    "    print('Error while trying to read video. Please check path again')\n",
    "\n",
    "frame_count = 0 # to count total frames\n",
    "total_fps = 0 # to get the final frames per second\n",
    "#while(cap.isOpened()):                      # read until end of video\n",
    "while(frame_count<200):\n",
    "    ret, image = cap.read()                 # capture each frame of the video\n",
    "    if ret == False:\n",
    "        break\n",
    "    #image = imutils.resize(image, width=700)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    start_time = time.time()      \n",
    "    boxes, labels, probs = predictor.predict(image, 10, 0.4)\n",
    "    end_time = time.time()\n",
    "    draw_boxes(image, boxes, labels, probs)\n",
    "    fps = 1 / (end_time - start_time)\n",
    "    total_fps += fps\n",
    "    fig=plt.figure(figsize=(12, 8))\n",
    "    clear_output(wait=True)\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "    print(\"frame {}, FPS : {:.3f}\".format(frame_count, fps))\n",
    "    frame_count += 1\n",
    "    wait_time = max(1, int(fps/4))\n",
    "cap.release()\n",
    "if(frame_count==0):\n",
    "    print(\"Erreur video\")\n",
    "else:\n",
    "    avg_fps = total_fps / frame_count\n",
    "print(f\"Average FPS: {avg_fps:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2ac31d",
   "metadata": {},
   "source": [
    "apprentissage avec FDDB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54c1309",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 train_ssd.py --datasets '/content/drive/MyDrive/FDDB_2010' --validation_dataset '/content/drive/MyDrive/FDDB_2010' --net mb2-ssd-lite --pretrained_ssd '/content/drive/MyDrive/deep learning/MobileNetSSD/models/mb2-ssd-lite-mp-0_686.pth' --num_epochs 70 --scheduler cosine --lr 0.01 --t_max 200 --validation_epochs 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7319037",
   "metadata": {},
   "source": [
    "evalution le model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd7f8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python eval_ssd.py --net mb2-ssd-lite  --dataset '/content/drive/MyDrive/FDDB_2010' --trained_model '/content/drive/MyDrive/deep learning/MobileNetSSD/models/mb2-ssd-lite-Epoch-45-Loss-1.0989911688698664.pth' --label_file '/content/drive/MyDrive/deep learning/MobileNetSSD/models/face-model-labels.txt' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dc372b",
   "metadata": {},
   "source": [
    "test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae76a29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from vision.ssd.vgg_ssd import create_vgg_ssd, create_vgg_ssd_predictor\n",
    "from vision.ssd.mobilenetv1_ssd import create_mobilenetv1_ssd, create_mobilenetv1_ssd_predictor\n",
    "from vision.ssd.mobilenetv1_ssd_lite import create_mobilenetv1_ssd_lite, create_mobilenetv1_ssd_lite_predictor\n",
    "from vision.ssd.squeezenet_ssd_lite import create_squeezenet_ssd_lite, create_squeezenet_ssd_lite_predictor\n",
    "from vision.ssd.mobilenet_v2_ssd_lite import create_mobilenetv2_ssd_lite, create_mobilenetv2_ssd_lite_predictor\n",
    "from vision.ssd.mobilenetv3_ssd_lite import create_mobilenetv3_large_ssd_lite, create_mobilenetv3_small_ssd_lite\n",
    "from vision.utils.misc import Timer\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d091d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/content/drive/MyDrive/deep learning/MobileNetSSD/models/mb2-ssd-lite-Epoch-45-Loss-1.0989911688698664.pth'\n",
    "label_path = '/content/drive/MyDrive/deep learning/MobileNetSSD/models/face-model-labels.txt'\n",
    "image_path = '/content/drive/MyDrive/deep learning/MobileNetSSD/facedetec.jpeg'\n",
    "\n",
    "class_names = [name.strip() for name in open(label_path).readlines()]\n",
    "\n",
    "net = create_mobilenetv2_ssd_lite(len(class_names), is_test=True)\n",
    "\n",
    "net.load(model_path)\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "predictor = create_mobilenetv2_ssd_lite_predictor(net, candidate_size=200, device=DEVICE)\n",
    "\n",
    "image = cv2.imread(image_path)\n",
    "#cv2.imshow('Image', image)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "boxes, labels, probs = predictor.predict(image, 15, 0.4)\n",
    "\n",
    "for i in range(boxes.size(0)):\n",
    "    box = boxes[i, :]\n",
    "    print(box)\n",
    "    cv2.rectangle(image, (box[0], box[1]), (box[2], box[3]), (255, 255, 0), 4)\n",
    "    #label = f\"\"\"{voc_dataset.class_names[labels[i]]}: {probs[i]:.2f}\"\"\"\n",
    "    label = f\"{class_names[labels[i]]}: {probs[i]:.2f}\"\n",
    "    cv2.putText(image, label,\n",
    "                (box[0] + 20, box[1] + 40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.5,  # font scale\n",
    "                (0, 255, 255),\n",
    "                1)  # line type\n",
    "path = \"run_ssd_example_output.jpg\"\n",
    "cv2.imwrite(path, image)\n",
    "print(f\"Found {len(probs)} objects. The output image is {path}\")\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cf3a7a",
   "metadata": {},
   "source": [
    "# implementation reconnaisance et detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0669ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import vision\n",
    "import torch\n",
    "from vision.ssd.vgg_ssd import create_vgg_ssd, create_vgg_ssd_predictor\n",
    "from vision.ssd.mobilenetv1_ssd import create_mobilenetv1_ssd, create_mobilenetv1_ssd_predictor\n",
    "from vision.ssd.mobilenetv1_ssd_lite import create_mobilenetv1_ssd_lite, create_mobilenetv1_ssd_lite_predictor\n",
    "from vision.ssd.squeezenet_ssd_lite import create_squeezenet_ssd_lite, create_squeezenet_ssd_lite_predictor\n",
    "from vision.ssd.mobilenet_v2_ssd_lite import create_mobilenetv2_ssd_lite, create_mobilenetv2_ssd_lite_predictor\n",
    "from vision.ssd.mobilenetv3_ssd_lite import create_mobilenetv3_large_ssd_lite, create_mobilenetv3_small_ssd_lite\n",
    "from vision.utils.misc import Timer\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "#from torchsummary import summary\n",
    "from __future__ import print_function\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ad0435",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a CNN\n",
    "#avec deux couche de convolution, trois couche complètement connectée, deux couche de pooling\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.name = \"CNN for face\"\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5)\n",
    "        self.pool1 = nn.MaxPool2d(2,2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5)\n",
    "        self.pool2 = nn.MaxPool2d(2,2)\n",
    "\n",
    "        #self.conv3 = nn.Conv2d(in_channels=32, out_channels=48, kernel_size=5)\n",
    "        #self.pool3 = nn.MaxPool2d(2,2)\n",
    "\n",
    "        self.fc1 = nn.Linear(32*22*22,120)\n",
    "        self.fc2 = nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))    # input(3, 100, 100) output(16, 96, 96)\n",
    "        x = self.pool1(x)            # output(16, 48, 48)\n",
    "        x = F.relu(self.conv2(x))    # output(32, 44, 44)\n",
    "        x = self.pool2(x)            # output(32, 22, 22)\n",
    "        #x = F.relu(self.conv3(x))    # output(48, 18, 18)\n",
    "        #x = self.pool3(x)            # output(48, 9, 9)\n",
    "\n",
    "        x = torch.flatten(x, 1)     #aplatissement\n",
    "\n",
    "        x = F.relu(self.fc1(x))      # output(120)\n",
    "        x = F.relu(self.fc2(x))      # output(84)\n",
    "        x = self.fc3(x)          # output(10)\n",
    "        return x\n",
    "\n",
    "#root\n",
    "train_dir = './imageLUO'\n",
    "\n",
    "#size\n",
    "im_w, im_h = 100, 100\n",
    "transform = transforms.Compose([\n",
    "                 transforms.Resize((im_w, im_h)),\n",
    "                 transforms.ToTensor()   #car la transformation qui suit porte sur des tenseurs\n",
    "                ])\n",
    "\n",
    "#import data\n",
    "full_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "#split dataset for train/test\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "#batch et loader data\n",
    "batch_size = 100\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#put data into graphics card\n",
    "#device = \"cpu\" #ou \"cuda\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "summary(model, (3, im_w, im_h))\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)    #utilisé par l'apprentissage (lr <-> learning rate)\n",
    "criterion = nn.CrossEntropyLoss()       #critère d'erreur en sortie (utilisé par l'apprentissage et le test)\n",
    "\n",
    "#function traning\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    data_len = len(train_loader.dataset)\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()                              #initialisation des gradients\n",
    "        output = model(data)                               #activation du réseau\n",
    "        loss = criterion(output, target)                   #calcul de l'erreur de sortie\n",
    "        loss.backward()                                    #rétro-propagation du gradient\n",
    "        optimizer.step()                                   #adaptation des poids des neurones\n",
    "        train_loss += loss.item()# * data.size(0)\n",
    "\n",
    "        pred = output.argmax(dim=1, keepdim=True)          # get the index of the max log-probability\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        if batch_idx % 200 == 0:\n",
    "            print('Train Epoch: {} [{}/{}]\\tTrain loss: {:.4f}'.format(\n",
    "                epoch, batch_idx * len(data), data_len, loss.item()))\n",
    "    train_loss /= data_len\n",
    "    accuracy = 100. * correct / data_len\n",
    "    print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain accuracy: {:.4f}'.format(\n",
    "                epoch, batch_idx * len(data), data_len, 100. * batch_idx / data_len, accuracy))\n",
    "    return train_loss, accuracy\n",
    "\n",
    "#function test\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss += criterion(output, target)#.item() * data.size(0)\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    loss /= len(test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    print('\\nTest set: Average test loss: {:.4f}, Test accuracy: ({:.2f}%)\\n'.format(loss, accuracy))\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132ab9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path ='./models/mb2-ssd-lite-Epoch-99-Loss-0.8589383926656511.pth'\n",
    "label_path = './models/face-model-labels.txt'\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.read()\n",
    "class_names = [name.strip() for name in open(label_path).readlines()]\n",
    "\n",
    "net = create_mobilenetv2_ssd_lite(len(class_names), is_test=True)\n",
    "\n",
    "net.load(model_path)\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "predictor = create_mobilenetv2_ssd_lite_predictor(net, candidate_size=200, device=DEVICE)\n",
    "\n",
    "timer = Timer()\n",
    "\n",
    "model = Net()                                    # re-création d'un réseau de neurones (identique au précédent)\n",
    "model.load_state_dict(torch.load('./models/save_model/best_model.pth'))    # chargement du modèle\n",
    "model.eval()\n",
    "\n",
    "def predict(model, image):\n",
    "        #image = cv2.resize(image, (100, 100))\n",
    "        np_img = np.array(image)                        # conversion en tableau numpy\n",
    "        image_tensor = torch.from_numpy(np_img)         # conversion en tenseur PyTorch\n",
    "        image_tensor = image_tensor.permute(2, 0, 1)    # nouvel ordre des dimensions\n",
    "        image_tensor = image_tensor.reshape([1, 3, np_img.shape[0], np_img.shape[1]]) # ajout d'une dimension (cf + haut)\n",
    "        output = model(image_tensor.float())        # application de l'image en entrée du réseau\n",
    "        index = output.data.cpu().numpy().argmax()\n",
    "        return index\n",
    "\n",
    "while True:\n",
    "    ret, image = cap.read()\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    timer.start()\n",
    "    boxes, labels, probs = predictor.predict(image, 15, 0.4)\n",
    "    interval = timer.end()\n",
    "    print('Time: {:.2f}s, Detect Objects: {:d}.'.format(interval, labels.size(0)))\n",
    "\n",
    "    for i in range(boxes.size(0)):\n",
    "          box = boxes[i, :]\n",
    "          print(box)\n",
    "          cv2.rectangle(image, (int(box[0]), int(box[1])), (int(box[2]), int(box[3]), (255, 255, 0), 4)\n",
    "          if box[1]>0 and box[0]>0 and box[2]>0 and box[3]>0:\n",
    "              rec = image[int(box[1]):int(box[3]),int(box[0]):int(box[2])]\n",
    "              #programme principal\n",
    "              #classe \"Emmanuel\" : incdex = 0 classe \"HUANGXinjian\" : index = 1 ; classe \"LUOWenqi\" ; index = 2 ：classe \"Valex\" index = 3 : classe \"unknown\" index = 4\n",
    "\n",
    "              index = predict(model, rec)\n",
    "              print('index : ', index)\n",
    "              #affichage du résultat sur l'image\n",
    "              classe = []    #nom des classes\n",
    "              classe.append('Emmanuel')\n",
    "              classe.append('HUANGXingjian')\n",
    "              classe.append('LUOWenqi')\n",
    "              classe.append('Valex')\n",
    "              classe.append('unknown')\n",
    "              test_loss, test_accuracy = test(model, device, test_loader)\n",
    "              label = f\"{str(classe[index])}: {test_accuracy:.2f}\"\n",
    "              cv2.putText(image, label,\n",
    "                            (int(box[0]) + 20, int(box[1]) + 40),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                            0.5,  # font scale\n",
    "                            (0, 0, 255),\n",
    "                            1)  # line type\n",
    "    cv2.imshow('annotated', image)\n",
    "    print(f\"Found {len(probs)} objects.\")\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd190549",
   "metadata": {},
   "source": [
    "# test communication SPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebd416b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pour Raspberry PI4\n",
    "import spidev\n",
    "\n",
    "spi=spidev.SpiDev()\n",
    "spi.open(0,0)\n",
    "spi_max_speed_hz=976000\n",
    "\n",
    "while True:\n",
    "    to_send = [0]\n",
    "    print(to_send)\n",
    "    spi.writebytes(to_send)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5ccf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour MSP430\n",
    "#include <msp430.h> \n",
    "unsigned char carac;\n",
    "void Init_SPI()\n",
    "{\n",
    "    UCB0CTL1 = UCSWRST;\n",
    "    P1DIR &=  ~BIT4; // CS input\n",
    "    P1OUT |=  BIT4; // CS high\n",
    "    P1SEL |= BIT7 | BIT5;  // Enable SIMO + SCLK\n",
    "    P1SEL2 |= BIT7 | BIT5; // Enable SIMO + SCLK\n",
    "    UCB0CTL0 |= UCCKPH | UCMSB | UCSYNC; // 3-pin, 8-bit SPI master\n",
    "    UCB0CTL0 &= ~UCMST;\n",
    "    UCB0CTL1 |= UCSSEL_2; // SMCLK\n",
    "    UCB0CTL1 &= ~UCSWRST;\n",
    "    UCB0BR0 = 26;\n",
    "    UCB0BR1 = 0;\n",
    "    IE2|= UCB0RXIE;\n",
    "}\n",
    "void RXSPI(unsigned char *c)\n",
    "{\n",
    "    while (!(IFG2 & UCB0RXIFG));              // buffer Rx USCI_B0 plein ?\n",
    "    *c = UCB0RXBUF;\n",
    "}\n",
    "void main(void ){\n",
    "    WDTCTL = WDTPW + WDTHOLD;\n",
    "    BCSCTL1= CALBC1_1MHZ; //frequence d’horloge 1MHz\n",
    "    DCOCTL= CALDCO_1MHZ;\n",
    "    Init_SPI();\n",
    "    P1SEL |= BIT0; // selection fonction TA0.1\n",
    "    P1SEL2 &= ~BIT0; // selection fonction TA0.1\n",
    "    P1DIR |= BIT6; // P1.6 en sortie\n",
    "    P1OUT &= ~BIT6;\n",
    "    //unsigned char c;\n",
    "    __enable_interrupt();\n",
    "    while(1);\n",
    "}\n",
    "#pragma vector=USCIAB0RX_VECTOR\n",
    "__interrupt void USCI0RX_ISR(void)\n",
    "{\n",
    "    while (!(IFG2 & UCB0RXIFG));\n",
    "    carac = UCB0RXBUF;\n",
    "    if(carac==0xED)\n",
    "    {\n",
    "       P1OUT |= BIT6;\n",
    "       //__delay_cycles(100000);\n",
    "    }\n",
    "    else\n",
    "    {\n",
    "       P1OUT &= ~BIT6;\n",
    "    }\n",
    "    IFG2 &= ~UCA0RXIFG; // Clear RX flag\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fca5392",
   "metadata": {},
   "source": [
    "# code de capture ultrason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2971d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "//------------------------------------------------------------------------------\n",
    "// DUAL-US Display 2 US sensors JYC-2022\n",
    "//------------------------------------------------------------------------------\n",
    "\n",
    "#include <msp430g2553.h> // specific part of msp430.h\n",
    "#include <intrinsics.h> // interrupt, delay, power mode ...\n",
    "#include <stdbool.h> // boolean definitions\n",
    "#include \"moteur.h\"\n",
    "\n",
    "unsigned int memo_capt1, memo_capt2;\n",
    "unsigned int diff_capt1, diff_capt2;\n",
    "unsigned int distance;\n",
    "\n",
    "//-- Timer Interrupt Service Routine -------------------------------------------\n",
    "#pragma vector = TIMER0_A0_VECTOR\n",
    "__interrupt void Timer_ISR(void)\n",
    "{\n",
    "unsigned int capt;\n",
    "\n",
    " capt = TA0CCR0;\n",
    "TA0CCTL0 ^= CM_3;\n",
    "\n",
    " diff_capt1 = capt - memo_capt1;\n",
    "memo_capt1 = capt;\n",
    "}\n",
    "\n",
    "//-- Main ----------------------------------------------------------------------\n",
    "void main(void)\n",
    "{\n",
    "WDTCTL = WDTPW | WDTHOLD; // stop watch-dog timer\n",
    "\n",
    " //Aff_Init();\n",
    "init();\n",
    "P1DIR = BIT0;\n",
    "P1OUT &= ~BIT0;\n",
    "\n",
    " // set SMCLK (Sub Main Clock) to 1MHz\n",
    "DCOCTL = CALDCO_1MHZ; BCSCTL1 = CALBC1_1MHZ;\n",
    "\n",
    " //.. Timer0 as signal measure ................................................\n",
    "P1SEL |= BIT1; // set P1.1 as TimerA-0 capture CCI0A\n",
    "P1SEL2 &= ~BIT1; // ...\n",
    "P1DIR &= ~BIT1; // set P1.1 as TimerA-0 input\n",
    "\n",
    " // set TimerA-0 to count at 1MHz\n",
    "TA0CTL = TASSEL_2 | ID_0 | MC_2 | 0;\n",
    "\n",
    " // set TimerA-0 as rise edge / CCI0A / Capture mode / Interrupt enable\n",
    "TA0CCTL0 = CM_1 | CCIS_0 | CAP | CCIE;\n",
    "\n",
    " P2SEL &= ~BIT7; // set P2.7 as I/O\n",
    "P2SEL2 &= ~BIT7;\n",
    "P2DIR |= BIT7; // set P2.7 as output\n",
    "P2OUT &= ~BIT7; // set P2.7 to false\n",
    "\n",
    "memo_capt1 = memo_capt2 = 0;\n",
    "diff_capt1 = diff_capt2 = 0;\n",
    "\n",
    " //............................................................................\n",
    "__enable_interrupt();\n",
    "\n",
    " while(true) // endless loop\n",
    "{\n",
    "unsigned int\n",
    "distance = diff_capt1 / 58;\n",
    "unsigned int i = 0;\n",
    "//Aff_valeur(convert_Hex_Dec(diff_capt1 >> 8));\n",
    "\n",
    " P2OUT |= BIT7; // set P1.0 to false\n",
    "__delay_cycles(1200); // delay 1ms\n",
    "P2OUT &= ~BIT7; // set P1.0 to false\n",
    "__delay_cycles(300000); // delay 250ms\n",
    "if(diff_capt1 < 836){\n",
    "for(i=0 ;i<60000;i++){\n",
    "    reculer();\n",
    "}\n",
    "for(i=0 ;i<50000;i++){\n",
    "                       tourner_droite();}\n",
    "avancer();\n",
    "P1OUT |= BIT0;\n",
    "}\n",
    "else if(diff_capt1 < 1672){\n",
    "    for(i=0 ;i<50000;i++){\n",
    "                           tourner_droite();}\n",
    "    avancer();\n",
    "    P1OUT |= BIT0;\n",
    "}\n",
    "else {\n",
    "    avancer();\n",
    "    P1OUT &= ~BIT0;\n",
    "}\n",
    " }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcc16fe",
   "metadata": {},
   "source": [
    "# code de MSP430"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54e52db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <msp430.h>\n",
    "#include <math.h>\n",
    "#include <ADC.h>\n",
    "unsigned char carac;\n",
    "unsigned int memo_capt1, memo_capt2;\n",
    "unsigned int diff_capt1, diff_capt2;\n",
    "unsigned int distance;\n",
    "void initRobot(){//Initialisation du robot (moteur, sens des roues, etc...)\n",
    "    P2DIR |= (BIT5|BIT4|BIT2|BIT1);\n",
    "    P2DIR &= ~(BIT3|BIT0);\n",
    "    P2OUT &= ~(BIT4|BIT2);\n",
    "    ADC_init();\n",
    "}\n",
    "void TIMER(int taccr0){\n",
    "    BCSCTL1= CALBC1_1MHZ; //frequence d’horloge 1MHz\n",
    "    DCOCTL= CALDCO_1MHZ; // \"\n",
    "    P1DIR |= BIT0; //BIT 0 du port 1 (LED de la Launchpad) en sortie\n",
    "    TA0CTL = 0|(TASSEL_2 | ID_3); //source SMCLK, pas de predivision ID_0\n",
    "    TA0CTL |= MC_3; //comptage en mode up\n",
    "    TA0CCR0 = taccr0;\n",
    "    while(!(TA0CTL & TAIFG)); //attente flag TAIFG a 1\n",
    "            TA0CTL &= ~TAIFG; //RAZ TAIFG\n",
    "}\n",
    "void initialiseUltrason()\n",
    "{\n",
    "    P1SEL |= BIT1; // set P1.1 as TimerA-0 capture CCI0A\n",
    "    P1SEL2 &= ~BIT1; // ...\n",
    "    P1DIR &= ~BIT1; // set P1.1 as TimerA-0 input\n",
    "\n",
    "     // set TimerA-0 to count at 1MHz\n",
    "    TA0CTL = TASSEL_2 | ID_0 | MC_2 | 0;\n",
    "\n",
    "     // set TimerA-0 as rise edge / CCI0A / Capture mode / Interrupt enable\n",
    "    TA0CCTL0 = CM_1 | CCIS_0 | CAP | CCIE;\n",
    "\n",
    "    P2SEL &= ~BIT7; // set P2.7 as I/O\n",
    "    P2SEL2 &= ~BIT7;\n",
    "    P2DIR |= BIT7; // set P2.7 as output\n",
    "    P2OUT &= ~BIT7; // set P2.7 to false\n",
    "}\n",
    "void attenteInstruction(float dureeAttente){\n",
    "    int entierSeconde = floor(dureeAttente);\n",
    "    float sec_dec = dureeAttente-entierSeconde;\n",
    "    int i=0;\n",
    "    for(i=0; i<entierSeconde; i++){\n",
    "        TIMER(62500);\n",
    "    }\n",
    "    int taccr0 = 62500*sec_dec;\n",
    "    TIMER(taccr0);\n",
    "}\n",
    "void PWM(int gauche, int droite){//Gestion de la PWM\n",
    "    P2DIR |= (BIT4|BIT2);\n",
    "    P2OUT&=~ (BIT4|BIT2);\n",
    "    TA1CTL = (TASSEL_2 | ID_0 | MC_1) ;\n",
    "    TA1CCR0 = 200; // determine la periode du signal\n",
    "    TA1CCR1 = gauche; // determine le rapport cyclique du signal\n",
    "    TA1CCR2 = droite;\n",
    "    TA1CCTL1 = OUTMOD_7;\n",
    "    TA1CCTL2 = OUTMOD_7;\n",
    "    P2SEL |= (BIT4|BIT2);\n",
    "    P2SEL2 &= ~ (BIT4|BIT2);\n",
    "}\n",
    "void initCapteurDroit(){ //init capteur de droite\n",
    "    P1DIR&=~BIT4;\n",
    "    P1REN|=BIT4;\n",
    "    P1OUT&=~BIT4;\n",
    "}\n",
    "void initCapteurGauche(){ //init capteur de gauche\n",
    "    P1DIR&=~BIT7;\n",
    "    P1REN|=BIT7;\n",
    "    P1OUT&=~BIT7;\n",
    "}\n",
    "void avancer(){\n",
    "    P2OUT &=~ BIT1;\n",
    "    P2OUT |= BIT5;\n",
    "}\n",
    "void reculer(){\n",
    "    P2OUT &=~ BIT5;\n",
    "    P2OUT |= BIT1;\n",
    "}\n",
    "void tournerGauche(){\n",
    "    P2OUT |= BIT5;\n",
    "    P2OUT |= BIT1;\n",
    "}\n",
    "void tournerDroite(){\n",
    "    P2OUT &=~ BIT5;\n",
    "    P2OUT &=~ BIT1;\n",
    "}\n",
    "void arret(){\n",
    "    PWM(0,0);\n",
    "}\n",
    "void demiTour(){\n",
    "    tournerGauche();\n",
    "    attenteInstruction(1);\n",
    "}\n",
    "void Init_SPI()\n",
    "{\n",
    "    UCB0CTL1 = UCSWRST;\n",
    "    P1DIR &=  ~BIT4; // CS input\n",
    "    P1OUT |=  BIT4; // CS high\n",
    "    P1SEL |= BIT7 | BIT5;  // Enable SIMO + SCLK\n",
    "    P1SEL2 |= BIT7 | BIT5; // Enable SIMO + SCLK\n",
    "    UCB0CTL0 |= UCCKPH | UCMSB | UCSYNC; // 3-pin, 8-bit SPI master\n",
    "    UCB0CTL0 &= ~UCMST;\n",
    "    UCB0CTL1 |= UCSSEL_2; // SMCLK\n",
    "    UCB0CTL1 &= ~UCSWRST;\n",
    "    UCB0BR0 = 26;\n",
    "    UCB0BR1 = 0;\n",
    "}\n",
    "void RXSPI(unsigned char *c)\n",
    "{\n",
    "    while (!(IFG2 & UCB0RXIFG));              // buffer Rx USCI_B0 plein ?\n",
    "    *c = UCB0RXBUF;\n",
    "}\n",
    "void main(void ){\n",
    "    WDTCTL = WDTPW + WDTHOLD;\n",
    "    BCSCTL1= CALBC1_1MHZ; //frequence d’horloge 1MHz\n",
    "    DCOCTL= CALDCO_1MHZ;\n",
    "    P1SEL |= BIT0; // selection fonction TA0.1\n",
    "    P1SEL2 &= ~BIT0; // selection fonction TA0.1\n",
    "    P1DIR |= BIT6; // P1.6 en sortie\n",
    "    P1OUT &= ~BIT6;\n",
    "    //initialisation fonctions robot et capteurs\n",
    "    initRobot();\n",
    "    initCapteurDroit();\n",
    "    initCapteurGauche();\n",
    "    Init_SPI();\n",
    "    memo_capt1 = memo_capt2 = 0;\n",
    "    diff_capt1 = diff_capt2 = 0;\n",
    "    __enable_interrupt();\n",
    "    //CODE ROBOT\n",
    "    //PWM(80,80);\n",
    "    //avancer();\n",
    "    //attenteInstruction(0.7);\n",
    "    //arret();\n",
    "    //attenteInstruction(1);\n",
    "    unsigned char c;\n",
    "    while(1){\n",
    "        PWM(80,80);\n",
    "        avancer();\n",
    "        unsigned int distance = diff_capt1 / 58;\n",
    "        unsigned int i = 0;\n",
    "        //Aff_valeur(convert_Hex_Dec(diff_capt1 >> 8));\n",
    "\n",
    "         P2OUT |= BIT7; // set P1.0 to false\n",
    "        __delay_cycles(1200); // delay 1ms\n",
    "        P2OUT &= ~BIT7; // set P1.0 to false\n",
    "        __delay_cycles(300000); // delay 250ms\n",
    "        if(diff_capt1 < 836){\n",
    "            for(i=0 ;i<15000000;i++){\n",
    "                arret();\n",
    "                while (!(IFG2 & UCB0RXIFG));\n",
    "                carac = UCB0RXBUF;\n",
    "                if(carac==0x00||carac==0x01||carac==0x02||carac==0x03||carac==0x04)\n",
    "                {\n",
    "                   P1OUT |= BIT6;\n",
    "                   //__delay_cycles(100000);\n",
    "                }\n",
    "                else\n",
    "                {\n",
    "                   P1OUT &= ~BIT6;\n",
    "                }\n",
    "            }\n",
    "            PWM(80,80);\n",
    "            tournerGauche();\n",
    "            __delay_cycles(100000);\n",
    "            PWM(80,80);\n",
    "            avancer();\n",
    "        }\n",
    "        else{\n",
    "            PWM(80,80);\n",
    "            avancer();\n",
    "        }\n",
    "    }\n",
    "}\n",
    "#pragma vector = TIMER0_A0_VECTOR\n",
    "__interrupt void Timer_ISR(void)\n",
    "{\n",
    "unsigned int capt;\n",
    "\n",
    " capt = TA0CCR0;\n",
    "TA0CCTL0 ^= CM_3;\n",
    "\n",
    " diff_capt1 = capt - memo_capt1;\n",
    "memo_capt1 = capt;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a36830",
   "metadata": {},
   "source": [
    "# code de RaspberryPI4 final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5ba0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import vision\n",
    "import torch\n",
    "from vision.ssd.vgg_ssd import create_vgg_ssd, create_vgg_ssd_predictor\n",
    "from vision.ssd.mobilenetv1_ssd import create_mobilenetv1_ssd, create_mobilenetv1_ssd_predictor\n",
    "from vision.ssd.mobilenetv1_ssd_lite import create_mobilenetv1_ssd_lite, create_mobilenetv1_ssd_lite_predictor\n",
    "from vision.ssd.squeezenet_ssd_lite import create_squeezenet_ssd_lite, create_squeezenet_ssd_lite_predictor\n",
    "from vision.ssd.mobilenet_v2_ssd_lite import create_mobilenetv2_ssd_lite, create_mobilenetv2_ssd_lite_predictor\n",
    "from vision.ssd.mobilenetv3_ssd_lite import create_mobilenetv3_large_ssd_lite, create_mobilenetv3_small_ssd_lite\n",
    "from vision.utils.misc import Timer\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "#from torchsummary import summary\n",
    "from __future__ import print_function\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "import spidev\n",
    "import time\n",
    "\n",
    "#create a CNN\n",
    "#avec deux couche de convolution, trois couche complètement connectée, deux couche de pooling\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.name = \"CNN for face\"\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5)\n",
    "        self.pool1 = nn.MaxPool2d(2,2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5)\n",
    "        self.pool2 = nn.MaxPool2d(2,2)\n",
    "\n",
    "        #self.conv3 = nn.Conv2d(in_channels=32, out_channels=48, kernel_size=5)\n",
    "        #self.pool3 = nn.MaxPool2d(2,2)\n",
    "\n",
    "        self.fc1 = nn.Linear(32*22*22,120)\n",
    "        self.fc2 = nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))    # input(3, 100, 100) output(16, 96, 96)\n",
    "        x = self.pool1(x)            # output(16, 48, 48)\n",
    "        x = F.relu(self.conv2(x))    # output(32, 44, 44)\n",
    "        x = self.pool2(x)            # output(32, 22, 22)\n",
    "        #x = F.relu(self.conv3(x))    # output(48, 18, 18)\n",
    "        #x = self.pool3(x)            # output(48, 9, 9)\n",
    "\n",
    "        x = torch.flatten(x, 1)     #aplatissement\n",
    "\n",
    "        x = F.relu(self.fc1(x))      # output(120)\n",
    "        x = F.relu(self.fc2(x))      # output(84)\n",
    "        x = self.fc3(x)          # output(10)\n",
    "        return x\n",
    "\n",
    "#root\n",
    "train_dir = './imageLUO'\n",
    "\n",
    "#size\n",
    "im_w, im_h = 100, 100\n",
    "transform = transforms.Compose([\n",
    "                 transforms.Resize((im_w, im_h)),\n",
    "                 transforms.ToTensor()   #car la transformation qui suit porte sur des tenseurs\n",
    "                ])\n",
    "\n",
    "#import data\n",
    "full_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "#split dataset for train/test\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "#batch et loader data\n",
    "batch_size = 100\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#put data into graphics card\n",
    "#device = \"cpu\" #ou \"cuda\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "summary(model, (3, im_w, im_h))\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)    #utilisé par l'apprentissage (lr <-> learning rate)\n",
    "criterion = nn.CrossEntropyLoss()       #critère d'erreur en sortie (utilisé par l'apprentissage et le test)\n",
    "\n",
    "#function traning\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    data_len = len(train_loader.dataset)\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()                              #initialisation des gradients\n",
    "        output = model(data)                               #activation du réseau\n",
    "        loss = criterion(output, target)                   #calcul de l'erreur de sortie\n",
    "        loss.backward()                                    #rétro-propagation du gradient\n",
    "        optimizer.step()                                   #adaptation des poids des neurones\n",
    "        train_loss += loss.item()# * data.size(0)\n",
    "\n",
    "        pred = output.argmax(dim=1, keepdim=True)          # get the index of the max log-probability\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        if batch_idx % 200 == 0:\n",
    "            print('Train Epoch: {} [{}/{}]\\tTrain loss: {:.4f}'.format(\n",
    "                epoch, batch_idx * len(data), data_len, loss.item()))\n",
    "    train_loss /= data_len\n",
    "    accuracy = 100. * correct / data_len\n",
    "    print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain accuracy: {:.4f}'.format(\n",
    "                epoch, batch_idx * len(data), data_len, 100. * batch_idx / data_len, accuracy))\n",
    "    return train_loss, accuracy\n",
    "\n",
    "#function test\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss += criterion(output, target)#.item() * data.size(0)\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    loss /= len(test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    print('\\nTest set: Average test loss: {:.4f}, Test accuracy: ({:.2f}%)\\n'.format(loss, accuracy))\n",
    "    return loss, accuracy\n",
    "\n",
    "model_path ='./models/mb2-ssd-lite-Epoch-99-Loss-0.8589383926656511.pth'\n",
    "label_path = './models/face-model-labels.txt'\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.read()\n",
    "class_names = [name.strip() for name in open(label_path).readlines()]\n",
    "\n",
    "net = create_mobilenetv2_ssd_lite(len(class_names), is_test=True)\n",
    "\n",
    "net.load(model_path)\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "predictor = create_mobilenetv2_ssd_lite_predictor(net, candidate_size=200, device=DEVICE)\n",
    "\n",
    "timer = Timer()\n",
    "\n",
    "model = Net()                                    # re-création d'un réseau de neurones (identique au précédent)\n",
    "model.load_state_dict(torch.load('./models/save_model/best_model.pth'))    # chargement du modèle\n",
    "model.eval()\n",
    "\n",
    "def predict(model, image):\n",
    "        #image = cv2.resize(image, (100, 100))\n",
    "        np_img = np.array(image)                        # conversion en tableau numpy\n",
    "        image_tensor = torch.from_numpy(np_img)         # conversion en tenseur PyTorch\n",
    "        image_tensor = image_tensor.permute(2, 0, 1)    # nouvel ordre des dimensions\n",
    "        image_tensor = image_tensor.reshape([1, 3, np_img.shape[0], np_img.shape[1]]) # ajout d'une dimension (cf + haut)\n",
    "        output = model(image_tensor.float())        # application de l'image en entrée du réseau\n",
    "        index = output.data.cpu().numpy().argmax()\n",
    "        return index\n",
    "\n",
    "spi=spidev.SpiDev()\n",
    "spi.open(0,0)\n",
    "spi_max_speed_hz=7629\n",
    "while True:\n",
    "    ret, image = cap.read()\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    timer.start()\n",
    "    boxes, labels, probs = predictor.predict(image, 15, 0.4)\n",
    "    interval = timer.end()\n",
    "    print('Time: {:.2f}s, Detect Objects: {:d}.'.format(interval, labels.size(0)))\n",
    "\n",
    "    for i in range(boxes.size(0)):\n",
    "          box = boxes[i, :]\n",
    "          print(box)\n",
    "          cv2.rectangle(image, (int(box[0]), int(box[1])), (int(box[2]), int(box[3]), (255, 255, 0), 4)\n",
    "          if box[1]>0 and box[0]>0 and box[2]>0 and box[3]>0:\n",
    "              rec = image[int(box[1]):int(box[3]),int(box[0]):int(box[2])]\n",
    "              #programme principal\n",
    "              #classe \"Emmanuel\" : incdex = 0 classe \"HUANGXinjian\" : index = 1 ; classe \"LUOWenqi\" ; index = 2 ：classe \"Valex\" index = 3 : classe \"unknown\" index = 4\n",
    "\n",
    "              index = predict(model, rec)\n",
    "              print('index : ', index)\n",
    "              for i in range(15000000):\n",
    "                        to_send = [index]\n",
    "                        print(to_send)\n",
    "                        spi.writebytes(to_send)\n",
    "\n",
    "              #affichage du résultat sur l'image\n",
    "              classe = []    #nom des classes\n",
    "              classe.append('Emmanuel')\n",
    "              classe.append('HUANGXingjian')\n",
    "              classe.append('LUOWenqi')\n",
    "              classe.append('Valex')\n",
    "              classe.append('unknown')\n",
    "              test_loss, test_accuracy = test(model, device, test_loader)\n",
    "              label = f\"{str(classe[index])}: {test_accuracy:.2f}\"\n",
    "              cv2.putText(image, label,\n",
    "                            (int(box[0]) + 20, int(box[1]) + 40),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                            0.5,  # font scale\n",
    "                            (0, 0, 255),\n",
    "                            1)  # line type\n",
    "    cv2.imshow('annotated', image)\n",
    "    print(f\"Found {len(probs)} objects.\")\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
